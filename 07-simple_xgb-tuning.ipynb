{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d064a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/codespace/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6196bc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2168910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3c93f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1722947787483, experiment_id='1', last_update_time=1722947787483, lifecycle_stage='active', name='earthquake_damage-experiment-1', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"earthquake_damage-experiment-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449b1755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█| 100/100 [1:06:45<00:00, 40.06s/trial, best loss: -0.7197017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/09 13:08:01 INFO mlflow.tracking._tracking_service.client: 🏃 View run stately-dog-247 at: http://127.0.0.1:5000/#/experiments/1/runs/9b8f702fcd71462ea418418f0de1c001.\n",
      "2024/08/09 13:08:01 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'learning_rate': 0.010553140697085937, 'max_depth': 5, 'n_estimators': 93, 'subsample': 0.554146890258596}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.log_param('data-preprocessing', 'target encoding')\n",
    "    \n",
    "    data_df = pd.read_csv('./data/train_values.csv')\n",
    "    data_df.drop(columns='building_id', inplace=True)\n",
    "\n",
    "    label_df = pd.read_csv('./data/train_labels.csv')\n",
    "    y = label_df['damage_grade'] - 1\n",
    "    \n",
    "#     balancing the labels using SMOTENC\n",
    "#     smotenc = SMOTENC(categorical_features=[7,8,9,10,11,12,13,14,25])\n",
    "#     train_x, train_y = smotenc.fit_resample(data_df, y)\n",
    "#     print(f\"balanced labels: {Counter(train_y)}\")\n",
    "\n",
    "    train_x = data_df\n",
    "    train_y = y\n",
    "    \n",
    "    # split the data into training and validation\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(train_x,\n",
    "                                                          train_y, \n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=49\n",
    "                                                         )\n",
    "    # encoding\n",
    "    # using target encoding\n",
    "    te = TargetEncoder(smooth='auto')\n",
    "    train_x = te.fit_transform(train_x, train_y)\n",
    "    \n",
    "    valid_x = te.fit_transform(valid_x, valid_y)\n",
    "    \n",
    "    \n",
    "    # using label encoding\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     cat_cols = train_x.select_dtypes('object').columns\n",
    "#     for col in cat_cols:\n",
    "#         train_x[col] = label_encoder.fit_transform(train_x[col])\n",
    "        \n",
    "#     label_encoder = LabelEncoder()\n",
    "#     cat_cols = valid_x.select_dtypes('object').columns\n",
    "#     for col in cat_cols:\n",
    "#         valid_x[col] = label_encoder.fit_transform(valid_x[col])\n",
    "    \n",
    "\n",
    "    # start hyperparam tuning\n",
    "    space = {\n",
    "    #         'max_depth': hp.quniform('max_depth', 2, 8, 1), # tree\n",
    "             'max_depth': hp.choice('max_depth', np.arange(2, 8, dtype=int)),\n",
    "             'learning_rate': hp.loguniform('learning_rate', -5, -2), #boosting\n",
    "             'subsample': hp.uniform('subsample', 0.5, 1), #stochastic\n",
    "             'n_estimators': hp.choice('n_estimators', np.arange(300, 400, dtype=int))\n",
    "            }\n",
    "\n",
    "    # objective function to minimize\n",
    "\n",
    "    def objective(params):\n",
    "        xgb_model = xgb.XGBClassifier(**params)\n",
    "\n",
    "        xgb_model.fit(train_x, train_y)\n",
    "\n",
    "        preds = xgb_model.predict(valid_x)\n",
    "\n",
    "        score = f1_score(valid_y, preds, average='micro')\n",
    "\n",
    "        return {'loss': -score,\n",
    "               'status': STATUS_OK}\n",
    "\n",
    "\n",
    "    # perform the optimization\n",
    "    trials = Trials()\n",
    "    \n",
    "    best_params = fmin(objective,\n",
    "                       space,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_evals=100,\n",
    "                       trials=trials)\n",
    "    \n",
    "#     mlflow.log_param('Best F1 score', best)\n",
    "    mlflow.log_param('Best params', best_params)\n",
    "    mlflow.log_param('learning rate', best_params['learning_rate'])\n",
    "    mlflow.log_param('subsample', best_params['subsample'])\n",
    "    mlflow.log_param('max depth', best_params['max_depth'])\n",
    "    mlflow.log_param('n_estimators', best_params['n_estimators'])\n",
    "    mlflow.log_metric('Best F1 score', trials.best_trial['result']['loss'])\n",
    "\n",
    "    print(f\"best params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best loss: -0.7177319297527532]\n",
    "# best params: {'learning_rate': 0.1341710726910401, 'max_depth': 5, 'subsample': 0.7574310350346926}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88300b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test_values.csv')\n",
    "test_df.drop(columns=['building_id'], inplace=True)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# cat_cols = test_df.select_dtypes('object').columns\n",
    "# for col in cat_cols:\n",
    "#     test_df[col] = label_encoder.fit_transform(test_df[col])\n",
    "\n",
    "# using target encoder\n",
    "test_x = te.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30777c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/anaconda3/lib/python3.9/site-packages/xgboost/core.py:723: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 64365, 3: 21726, 1: 777})\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(best_params,\n",
    "#                         early_stopping_rounds=50,\n",
    "#                         n_estimators=500\n",
    "                       )\n",
    "\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "preds = clf.predict(test_x)\n",
    "pred_labels = [p+1 for p in preds]\n",
    "print(Counter(pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f90f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test_values.csv')\n",
    "results = pd.DataFrame(data={'building_id':test_df['building_id'],\n",
    "                             'damage_grade':pred_labels\n",
    "                            },\n",
    "                      dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af256955",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('predictions.csv',\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc28d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
