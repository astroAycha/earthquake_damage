{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86d064a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTENC\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6196bc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2168910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1722946156504, experiment_id='0', last_update_time=1722946156504, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e3c93f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/06 12:36:27 INFO mlflow.tracking.fluent: Experiment with name 'earthquake_damage-experiment-1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1722947787483, experiment_id='1', last_update_time=1722947787483, lifecycle_stage='active', name='earthquake_damage-experiment-1', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"earthquake_damage-experiment-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "449b1755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆ| 100/100 [30:46<00:00, 18.47s/trial, best loss: -0.738926337\n",
      "best params: {'learning_rate': 0.11790157411707712, 'max_depth': 5, 'n_estimators': 73, 'subsample': 0.7373874185036384}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.log_param('data-preprocessing', 'label encoding')\n",
    "    \n",
    "    data_df = pd.read_csv('./data/train_values.csv')\n",
    "    data_df.drop(columns='building_id', inplace=True)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    cat_cols = data_df.select_dtypes('object').columns\n",
    "    for col in cat_cols:\n",
    "        data_df[col] = label_encoder.fit_transform(data_df[col])\n",
    "\n",
    "    label_df = pd.read_csv('./data/train_labels.csv')\n",
    "    y = label_df['damage_grade'] - 1  \n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data_df,\n",
    "                                                          y, \n",
    "                                                          test_size=0.3,\n",
    "                                                          random_state=49\n",
    "                                                         )\n",
    "\n",
    "    space = {\n",
    "    #         'max_depth': hp.quniform('max_depth', 2, 8, 1), # tree\n",
    "             'max_depth': hp.choice('max_depth', np.arange(2, 8, dtype=int)),\n",
    "             'learning_rate': hp.loguniform('learning_rate', -5, -2), #boosting\n",
    "             'subsample': hp.uniform('subsample', 0.5, 1), #stochastic\n",
    "             'n_estimators': hp.choice('n_estimators', np.arange(300, 400, dtype=int))\n",
    "            }\n",
    "\n",
    "    # objective function to minimize\n",
    "\n",
    "    def objective(params):\n",
    "        xgb_model = xgb.XGBClassifier(**params)\n",
    "\n",
    "        xgb_model.fit(train_x, train_y)\n",
    "\n",
    "        preds = xgb_model.predict(valid_x)\n",
    "\n",
    "        score = f1_score(valid_y, preds, average='micro')\n",
    "\n",
    "        return {'loss': -score,\n",
    "               'status': STATUS_OK}\n",
    "\n",
    "\n",
    "    # perform the optimization\n",
    "    trials = Trials()\n",
    "    \n",
    "    best_params = fmin(objective,\n",
    "                       space,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_evals=100,\n",
    "                       trials=trials)\n",
    "    \n",
    "#     mlflow.log_param('Best F1 score', best)\n",
    "    mlflow.log_param('Best params', best_params)\n",
    "    mlflow.log_param('learning rate', best_params['learning_rate'])\n",
    "    mlflow.log_param('subsample', best_params['subsample'])\n",
    "    mlflow.log_param('max depth', best_params['max_depth'])\n",
    "    mlflow.log_param('n_estimators', best_params['n_estimators'])\n",
    "    mlflow.log_metric('Best F1 score', trials.best_trial['result']['loss'])\n",
    "\n",
    "    print(f\"best params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best loss: -0.7177319297527532]\n",
    "# best params: {'learning_rate': 0.1341710726910401, 'max_depth': 5, 'subsample': 0.7574310350346926}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e88300b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test_values.csv')\n",
    "test_df.drop(columns=['building_id'], inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "cat_cols = test_df.select_dtypes('object').columns\n",
    "for col in cat_cols:\n",
    "    test_df[col] = label_encoder.fit_transform(test_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30777c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/anaconda3/lib/python3.9/site-packages/xgboost/core.py:723: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 58150, 3: 23162, 1: 5556})\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(best_params,\n",
    "#                         early_stopping_rounds=50,\n",
    "#                         n_estimators=500\n",
    "                       )\n",
    "\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "preds = clf.predict(test_df)\n",
    "pred_labels = [p+1 for p in preds]\n",
    "print(Counter(pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9f90f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test_values.csv')\n",
    "results = pd.DataFrame(data={'building_id':test_df['building_id'],\n",
    "                             'damage_grade':pred_labels\n",
    "                            },\n",
    "                      dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af256955",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('predictions.csv',\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7f9dc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7366495695885189"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial['result']['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc28d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
